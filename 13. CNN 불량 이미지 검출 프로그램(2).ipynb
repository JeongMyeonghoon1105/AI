{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a150f49",
   "metadata": {},
   "source": [
    "# 13. CNN 불량 이미지 검출 프로그램(2)\n",
    "데이터셋의 불량 유형을 2가지로 설정   \n",
    "VGG16 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5495469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a514d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a03e0",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "데이터를 증폭하기 위한 기법  \n",
    "* Rotation Range : 이미지 회전 각도 범위\n",
    "* Width/Height Shift : 수평/수직 방향으로의 임의적인 평행이동의 범위\n",
    "* Rescale : [0, 255] 범위의 RGB 값을 [0, 1] 범위로 정규화하는 전처리 과정\n",
    "* Shear Range : 임의 전단 변환(직사각형 형태의 이미지를 평행사변형 형태로 변환) 범위\n",
    "* Zoom Range : 확대 및 축소 범위\n",
    "* Horizontal Flip : 이미지 수평 반전 허용 여부\n",
    "* Fill Mode : 이미지를 조작할 때 발생하는 공백을 채우는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a6ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 생성 완료\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=3,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.01,\n",
    "    zoom_range=0.01,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "for i in range(1, 21):\n",
    "    path = 'CNN/Train/Broken/Broken' + str(i) + '.jpg'\n",
    "    img = load_img(path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir='CNN/Train/Broken', save_prefix='Broken', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 50:\n",
    "            break\n",
    "            \n",
    "for i in range(1, 21):\n",
    "    path = 'CNN/Train/Circle/Circle' + str(i) + '.jpg'\n",
    "    img = load_img(path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir='CNN/Train/Circle', save_prefix='Circle', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 50:\n",
    "            break\n",
    "\n",
    "for i in range(1, 21):\n",
    "    path = 'CNN/Train/Original/Original' + str(i) + '.jpg'\n",
    "    img = load_img(path)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir='CNN/Train/Original', save_prefix='Original', save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 50:\n",
    "            break\n",
    "            \n",
    "print('이미지 생성 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f21b5",
   "metadata": {},
   "source": [
    "## VGG16 모델 불러오기\n",
    "* VGG16은 16개의 층으로 이루어진 VGGNet(쉬운 구조와 좋은 성능으로 인해 널리 사용되는 CNN 네트워크)   \n",
    "* 입력된 이미지 데이터셋을 1000개의 클래스로 분류하도록 학습된 모델\n",
    "* 이 모델을 활용하여 원하는 개수의 클래스로 이미지를 분류하는 모델을 제작할 수 있음\n",
    "* 224 X 224 사이즈로 이미지 인풋을 넣어주어야 하며, 커널 사이즈는 3 X 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f97c1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 모델 불러오기\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model = VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7abc81",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d0d07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 Layer 데이터화\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# Layer 추가\n",
    "x = layer_dict['block5_pool'].output\n",
    "\n",
    "# Cov2D Layer 추가\n",
    "x = Conv2D(filters = 64, kernel_size=(3, 3), activation='relu')(x)\n",
    "\n",
    "# MaxPooling2D Layer 추가\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Flatten Layer 추가\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Fully Connected Layer 추가\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# 새 모델 정의\n",
    "new_model = Model(inputs = model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35062ffd",
   "metadata": {},
   "source": [
    "## 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "745f8847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 5, 64)          294976    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2048)              526336    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,637,251\n",
      "Trainable params: 2,922,563\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 사전에 학습된 가중치를 그대로 사용\n",
    "for layer in new_model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "# 컴파일 옵션\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec8394",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "282b157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2954 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = './CNN/Train'\n",
    "\n",
    "# [0, 1] 범위로 정규화\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 데이터 구조 생성\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=16, directory=train_dir,\n",
    "                                                                   target_size=(224, 224), class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e5906",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eaeb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 61/185 [========>.....................] - ETA: 21:40 - batch: 30.0000 - size: 15.9016 - loss: 6.8499e-05 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = new_model.fit(train_data_gen, epochs=3)\n",
    "\n",
    "# 모델 저장\n",
    "new_model.save('Model/newVGG16.h5')                        \n",
    "\n",
    "# 최종 결과 리포트\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69268f4b",
   "metadata": {},
   "source": [
    "## 예측 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3374ce2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.455566e-14 9.999939e-01 6.105926e-06]]\n"
     ]
    }
   ],
   "source": [
    "# 저장 모델 불러오기\n",
    "new_model = load_model(\"Model/Model.h5\")\n",
    "\n",
    "img = np.resize(cv2.imread('CNN/Test/Circle4.jpg', cv2.IMREAD_COLOR), (224, 224, 3))\n",
    "inputData = []\n",
    "inputData.append(img)\n",
    "# print(new_model.predict(np.array(inputData)))\n",
    "\n",
    "maximum = 0.0\n",
    "maxIndex = 0\n",
    "for array in new_model.predict(np.array(inputData)):\n",
    "    for index, predict in enumerate(array):\n",
    "        if maximum < float(predict):\n",
    "            maximum = float(predict)\n",
    "            maxIndex = index\n",
    "            \n",
    "if maxIndex == 0:\n",
    "    print('결절형 결함 발생')\n",
    "elif maxIndex == 1:\n",
    "    print('원형 결함 발생')\n",
    "else:\n",
    "    print('정상')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d5347",
   "metadata": {},
   "source": [
    "## 예측 결과 전체 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab4339d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\t[nan nan nan]\n",
      "Broken4.jpg\t[1. 0. 0.]\n",
      "Original.jpg\t[1.3475853e-09 3.7665460e-19 1.0000000e+00]\n",
      "Broken5.jpg\t[1. 0. 0.]\n",
      "Circle4.jpg\t[8.455501e-14 9.999939e-01 6.105880e-06]\n",
      "Circle.jpg\t[1.3459718e-13 1.0000000e+00 0.0000000e+00]\n",
      "Circle3.jpg\t[2.0007302e-37 1.0000000e+00 0.0000000e+00]\n",
      "Broken2.jpg\t[1. 0. 0.]\n",
      "Broken3.jpg\t[1. 0. 0.]\n",
      "Circle2.jpg\t[9.280094e-21 1.000000e+00 0.000000e+00]\n",
      "Broken.jpg\t[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 불러올 이미지들을 저장할 리스트\n",
    "imgs = []\n",
    "\n",
    "# 이미지들의 파일명들을 저장할 리스트\n",
    "imageNames = []\n",
    "\n",
    "# 이미지 불러오기\n",
    "for imageName in os.listdir('./CNN/Test/'):\n",
    "    # 불러올 이미지의 경로를 변수에 저장\n",
    "    path = './CNN/Test/' + imageName\n",
    "    \n",
    "    # 이미지 불러오기\n",
    "    img = np.resize(cv2.imread(path, cv2.IMREAD_COLOR), (224, 224, 3))\n",
    "    imgs.append(img)\n",
    "\n",
    "    # 불러온 이미지의 파일명을 리스트에 저장\n",
    "    imageNames.append(imageName)\n",
    "\n",
    "for i, result in enumerate(new_model.predict(np.array(imgs))):\n",
    "    print(imageNames[i], end='\\t')\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
